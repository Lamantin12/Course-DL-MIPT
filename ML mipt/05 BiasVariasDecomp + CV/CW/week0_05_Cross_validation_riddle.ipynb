{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Credits: this notebook origin (shared under MIT license) belongs to [ML course at ICL](https://github.com/yandexdataschool/MLatImperial2020) held by Yandex School of Data Analysis. Special thanks to the course team for making it available online.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ij_zY4soDF2Z"
   },
   "source": [
    "## week0_05: Cross-validation riddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qUCsY5OlDJPl"
   },
   "source": [
    "Here's a small example of cross-validation done wrongly. Can you spot the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSUzkXsC-R4H"
   },
   "outputs": [],
   "source": [
    "# Some imports...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZyDp3Xc_DaDM"
   },
   "source": [
    "**Plan:**\n",
    "\n",
    "- Let's create a binary classification dataset where targets are completely independent from the features\n",
    "  - *(i.e. no model could ever predict them well)*\n",
    "- We'll do some simple feature selection\n",
    "- And cross-validate a model on this data\n",
    "\n",
    "**Q:** what accuracy do we expect (classes are even)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHx51DKP8Rcf"
   },
   "source": [
    "We'll start from writing a class to select the best features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRNmKZJJ8W7x"
   },
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    def __init__(self, num_features):\n",
    "        self.n = num_features # number of best features to select\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Select features that describe the targets best, i.e. have\n",
    "        # highest correlation with them: \n",
    "        covariance = ((X - X.mean(axis=0)) * (y[:,np.newaxis] - y.mean())).mean(axis=0) #Here we have data leak\n",
    "        self.best_feature_ids = np.argsort(np.abs(covariance))[-self.n:]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:,self.best_feature_ids]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6mu9gHgNBk_V",
    "outputId": "020bdc20-04e3-45c3-a3a7-a4c2cf9139e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.9400000000000001\n"
     ]
    }
   ],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "\n",
    "# Dataset generation\n",
    "X = np.random.normal(size=(N, num_features_total))\n",
    "y = np.random.randint(2, size=N)\n",
    "\n",
    "# Feature selection:\n",
    "X_best = FeatureSelector(num_features_best).fit_transform(X, y) #Here we have data leak by using all data, \n",
    "                                                                #and then cross-validating on its part\n",
    "\n",
    "# Simple classification model\n",
    "model = LinearSVC()\n",
    "\n",
    "# Estimatin accuracy using cross-validation:\n",
    "cv_score = cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "print(f\"CV score is {cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afadN3ZVFKjF"
   },
   "source": [
    "What's going on?! Why accuracy is so high?\n",
    "\n",
    "Maybe it just happened by chance? Let's repeat this experiment many times and histogram the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "QDbOMXnuC6uw",
    "outputId": "597d41e7-482b-4f6a-8565-316644c1b04e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANG0lEQVR4nO3db6hk9X3H8fenMXnQaNO13sjGaG4Tgo0UqrLYFktICUn9A1UDhQhNxKZsArEopA8W+yBCn2zaap6kCCtKpKQpLVFiMbTKIkigpL1rV13ZpJpkk6rb3U0taB8VzbcP5txwud57Z/bOzL3zje8XDDPzm3PmfPbsjw9nzp1zb6oKSVI/v7DbASRJ22OBS1JTFrgkNWWBS1JTFrgkNXXOTm7sggsuqOXl5Z3cpCS1d+TIkZ9U1dL68R0t8OXlZVZWVnZyk5LUXpIfbTTuKRRJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmxhZ4kouTPJHkeJLnktw+jN+V5KUkR4fbdfOPK0laNcn3wF8HvlBVTyU5DziS5PHhtS9X1V/NL54kaTNjC7yqTgInh8evJTkOXDTvYJKkrZ3VlZhJloErgO8AVwO3Jfk0sMLoKP1/NlhnP7Af4JJLLpk2rzQXywce3bVtnzh4/a5tW71N/EPMJOcC3wDuqKpXgXuBDwCXMzpCv3uj9arqUFXtq6p9S0tvupRfkrRNExV4krczKu+vVdVDAFV1qqreqKqfAvcBV80vpiRpvUm+hRLgfuB4Vd2zZnzvmsVuAo7NPp4kaTOTnAO/GvgU8GySo8PYncDNSS4HCjgBfHYO+SRJm5jkWyjfBrLBS9+afRxJ0qS8ElOSmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJampsQWe5OIkTyQ5nuS5JLcP4+cneTzJ88P9nvnHlSStmuQI/HXgC1X1IeC3gM8nuQw4AByuqg8Ch4fnkqQdMrbAq+pkVT01PH4NOA5cBNwAPDgs9iBw45wySpI2cFbnwJMsA1cA3wEurKqTMCp54N2brLM/yUqSlTNnzkwZV5K0auICT3Iu8A3gjqp6ddL1qupQVe2rqn1LS0vbyShJ2sBEBZ7k7YzK+2tV9dAwfCrJ3uH1vcDp+USUJG1kkm+hBLgfOF5V96x56RHgluHxLcA3Zx9PkrSZcyZY5mrgU8CzSY4OY3cCB4G/T/IZ4MfAH8wloSRpQ2MLvKq+DWSTlz862ziSpEl5JaYkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTFrgkNWWBS1JTYws8yQNJTic5tmbsriQvJTk63K6bb0xJ0nqTHIF/Fbhmg/EvV9Xlw+1bs40lSRpnbIFX1ZPAKzuQRZJ0FqY5B35bkmeGUyx7ZpZIkjSRc7a53r3AnwM13N8N/NFGCybZD+wHuOSSS7a5Ob1VLB94dLcjvGXs5r4+cfD6Xdv2z5NtHYFX1amqeqOqfgrcB1y1xbKHqmpfVe1bWlrabk5J0jrbKvAke9c8vQk4ttmykqT5GHsKJcnXgY8AFyR5Efgi8JEklzM6hXIC+Oz8IkqSNjK2wKvq5g2G759DFknSWfBKTElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqygKXpKYscElqamyBJ3kgyekkx9aMnZ/k8STPD/d75htTkrTeJEfgXwWuWTd2ADhcVR8EDg/PJUk7aGyBV9WTwCvrhm8AHhwePwjcONtYkqRxtnsO/MKqOgkw3L97swWT7E+ykmTlzJkz29ycJGm9uf8Qs6oOVdW+qtq3tLQ0781J0lvGdgv8VJK9AMP96dlFkiRNYrsF/ghwy/D4FuCbs4kjSZrUJF8j/DrwL8ClSV5M8hngIPCxJM8DHxueS5J20DnjFqiqmzd56aMzziJJOgteiSlJTVngktTU2FMoguUDj+52hB114uD1ux1B0gQ8ApekpixwSWrKApekpixwSWrKApekpixwSWrKApekpixwSWrKC3n0Jm+1C5ekrjwCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6Sm/B64tMveit+7361/88/bHyvxCFySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJakpC1ySmrLAJampqX6ZVZITwGvAG8DrVbVvFqEkSePN4rcR/m5V/WQG7yNJOgueQpGkpqYt8AIeS3Ikyf6NFkiyP8lKkpUzZ85MuTlJ0qppC/zqqroSuBb4fJIPr1+gqg5V1b6q2re0tDTl5iRJq6Yq8Kp6ebg/DTwMXDWLUJKk8bZd4EnemeS81cfAx4FjswomSdraNN9CuRB4OMnq+/xtVf3TTFJJksbadoFX1Q+A35hhFknSWfBrhJLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLUlAUuSU1Z4JLU1Cz+pJoktbB84NFd2/aJg9fP/D09ApekpixwSWrKApekpixwSWrKApekpixwSWrKApekptp8D3w3v78pSYvII3BJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJasoCl6SmLHBJamqqAk9yTZLvJXkhyYFZhZIkjbftAk/yNuCvgWuBy4Cbk1w2q2CSpK1NcwR+FfBCVf2gqv4P+DvghtnEkiSNM80fdLgI+M81z18EfnP9Qkn2A/uHp/+b5HtTbHOcC4CfzPH958HM89ctL5h5p+xY5nxpqtXft9HgNAWeDcbqTQNVh4BDU2xnYklWqmrfTmxrVsw8f93ygpl3SsfMa01zCuVF4OI1z98LvDxdHEnSpKYp8H8DPpjkV5O8A/gk8MhsYkmSxtn2KZSqej3JbcA/A28DHqiq52aWbHt25FTNjJl5/rrlBTPvlI6ZfyZVbzptLUlqwCsxJakpC1ySmlrYAh93mX6SdyX5xyRPJ3kuya3D+MVJnkhyfBi/fc06dyV5KcnR4XbdImQeXjuR5Nkh18qa8fOTPJ7k+eF+zyJkTnLpmv14NMmrSe4YXtvt/bwnycNJnknyr0l+fdy689zP28274HN5q328qHN5s/28a3N5alW1cDdGPxT9PvB+4B3A08Bl65a5E/jS8HgJeGVYdi9w5TB+HvAfq+sCdwF/umiZh+cngAs2eN+/AA4Mjw+srr8Imde9z38B71uQ/fyXwBeHx78GHB637rz285R5F3kub5h5wefyppl3Yy7P4raoR+CTXKZfwHlJApzLqFher6qTVfUUQFW9BhxndNXowmYe8743AA8Ojx8EbpxZ4tll/ijw/ar60QyzbWaSzJcBhwGq6rvAcpILx6w7r/287bwLPpc328db2e25PEnmnZzLU1vUAt/oMv31E/crwIcYXTz0LHB7Vf107QJJloErgO+sGb5t+Aj1wIw/wk2buYDHkhzJ6NcPrLqwqk4CDPfvXqDMqz4JfH3d2G7u56eBTwAkuYrRZcjvHbPuvPbzNHl/ZgHn8laZF3Uuj93P7OxcntqiFvgkl+n/HnAUeA9wOfCVJL/0szdIzgW+AdxRVa8Ow/cCHxiWPwncvUCZr66qKxn9dsfPJ/nwDLNtZhb7+R3A7wP/sGad3d7PB4E9SY4CfwL8O6NPDRP9+ocZmybv6A0Wcy5vlXlR5/K4/bzTc3lqi1rgk1ymfyvwUI28APyQ0Xktkryd0YT/WlU9tLpCVZ2qqjeGI8j7GH3sWojMVfXycH8aeHhNtlNJ9g7/rr3A6UXJPLgWeKqqTq0O7PZ+rqpXq+rWqroc+DSjc/c/HLPuvPbzNHkXdi5vlXlR5/JWmQc7PZentqgFPsll+j9mdL6K4TzWpcAPhnO19wPHq+qetSusTp7BTcCxBcn8ziTnDePvBD6+JtsjwC3D41uAby5C5jWv38y6j5y7vZ+T/PLwGsAfA08OR65brTuv/bztvIs8l7fIvLBzeYt5sWqn5/L0dvMnqFvdgOsY/dT9+8CfDWOfAz43PH4P8Bij87LHgD8cxn+H0UenZxh99D8KXDe89jfD8s8w+s/duyCZ38/o/NzTwHOr6w6v/QqjH7w8P9yfvwiZh9d+Efhv4F3r3nO39/NvD/vru8BDwJ6t1p33ft5u3gWfy5tlXuS5vNW82JW5PO3NS+klqalFPYUiSRrDApekpixwSWrKApekpixwSWrKApekpixwSWrq/wFK90gRu2sngQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features_total = 1000\n",
    "num_features_best = 100\n",
    "\n",
    "N = 100\n",
    "def experiment():\n",
    "    # Dataset generation\n",
    "    X = np.random.normal(size=(N, num_features_total))\n",
    "    y = np.random.randint(2, size=N)\n",
    "\n",
    "    # Feature selection:\n",
    "    X_best = FeatureSelector(num_features_best).fit_transform(X, y)\n",
    "\n",
    "    # Simple classification model\n",
    "    model = LinearSVC()\n",
    "\n",
    "  # Estimatin accuracy using cross-validation:\n",
    "    return cross_val_score(model, X_best, y, scoring='accuracy', cv=10, n_jobs=-1).mean()\n",
    "\n",
    "results = [experiment() for _ in range(100)]\n",
    "plt.hist(results, bins=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8bLaEypoF5pb"
   },
   "source": [
    "Can you explain and fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's dangerous to go alone. Take this!\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = Pipeline(steps = [\n",
    "    ('preproc', FeatureSelector(num_features_best)),\n",
    "    ('svc', LinearSVC())    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5199999999999999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.fit(X, y)\n",
    "cross_val_score(pip, X, y, scoring='accuracy', cv=10, n_jobs=-1).mean() #With no dataleaks it looks line this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(pip.predict(X), y))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Cross-validation riddle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
